{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GvD743QZxaMk"
      },
      "outputs": [],
      "source": [
        "!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip\n",
        "!unzip EuroSAT.zip -d EuroSAT/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUy5PuqU0fPT"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  images, labels = zip(*batch)\n",
        "  return list(images), torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6wnxSmjx_jf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "from transformers import (\n",
        "    AutoImageProcessor,\n",
        "    AutoModelForImageClassification,\n",
        "    AutoModelForPreTraining,\n",
        "    AutoModel,\n",
        "    VitMatteForImageMatting\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_dir = \"/content/EuroSAT/2750\"\n",
        "\n",
        "dataset = datasets.ImageFolder(root=data_dir)\n",
        "classes = dataset.classes\n",
        "num_classes = len(classes)\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "valid_size = 0.2\n",
        "batch_size = 32\n",
        "num_data = len(dataset)\n",
        "indices = list(range(num_data))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_data))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=valid_sampler,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7Fn46TR0y9U"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, processor, dataloader, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in dataloader:\n",
        "        labels = labels.to(device)\n",
        "        inputs = processor(images, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs[\"loss\"]\n",
        "        logits = outputs[\"logits\"]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "        _, predicted = logits.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, processor, dataloader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            labels = labels.to(device)\n",
        "            inputs = processor(images, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs[\"loss\"]\n",
        "            logits = outputs[\"logits\"]\n",
        "\n",
        "            val_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = logits.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = 100.0 * correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def evaluate_model(model, processor, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            labels = labels.to(device)\n",
        "            inputs = processor(images, return_tensors=\"pt\").to(device)\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs[\"logits\"]\n",
        "            _, predicted = logits.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return all_labels, all_preds\n",
        "\n",
        "def plot_confusion_matrix(all_labels, all_preds, classes):\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', values_format='d')\n",
        "    plt.title(\"Confusion Matrix on Validation Set\")\n",
        "    plt.show()\n",
        "\n",
        "def print_classification_report(all_labels, all_preds, classes):\n",
        "    report = classification_report(all_labels, all_preds, target_names=classes)\n",
        "    print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuiDVxmQ4XVY"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, processor, train_loader, valid_loader, epochs=35, lr=1e-3, wd=1e-4):\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    train_losses, train_accuracies = [], []\n",
        "    val_losses, val_accuracies = [], []\n",
        "\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train_one_epoch(model, processor, train_loader, optimizer)\n",
        "        val_loss, val_acc = validate(model, processor, valid_loader)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\\n\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Training and Validation Accuracy\")\n",
        "    plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    all_labels, all_preds = evaluate_model(model, processor, valid_loader)\n",
        "    plot_confusion_matrix(all_labels, all_preds, classes)\n",
        "    print_classification_report(all_labels, all_preds, classes)\n",
        "\n",
        "    return best_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEz7keIH3gWn"
      },
      "outputs": [],
      "source": [
        "def get_deit_model(num_classes):\n",
        "    from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "    processor = AutoImageProcessor.from_pretrained(\n",
        "        \"facebook/deit-small-patch16-224\",\n",
        "        use_fast=True\n",
        "    )\n",
        "    model = AutoModelForImageClassification.from_pretrained(\n",
        "        \"facebook/deit-small-patch16-224\",\n",
        "        num_labels=num_classes,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    model.to(device)\n",
        "    return model, processor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-J1y9Iu6LvK"
      },
      "outputs": [],
      "source": [
        "print(\"=== DeiT ===\")\n",
        "deit_model, deit_processor = get_deit_model(num_classes)\n",
        "deit_acc = train_and_evaluate(deit_model, deit_processor, train_loader, valid_loader)\n",
        "\n",
        "print(f\"DeiT Val Acc: {deit_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWyetc9FRuyz"
      },
      "outputs": [],
      "source": [
        "def get_swin_model(num_classes):\n",
        "    from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "    processor = AutoImageProcessor.from_pretrained(\n",
        "        \"microsoft/swin-tiny-patch4-window7-224\",\n",
        "        use_fast=True\n",
        "        )\n",
        "    model = AutoModelForImageClassification.from_pretrained(\n",
        "        \"microsoft/swin-tiny-patch4-window7-224\",\n",
        "        num_labels=num_classes,\n",
        "        ignore_mismatched_sizes=True\n",
        "        )\n",
        "    model.to(device)\n",
        "    return model, processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXkPDi7sSiGG"
      },
      "outputs": [],
      "source": [
        "print(\"=== Swin Transformer ===\")\n",
        "swin_model, swin_processor = get_swin_model(num_classes)\n",
        "swin_acc = train_and_evaluate(swin_model, swin_processor, train_loader, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llo2nOE6SmKB"
      },
      "outputs": [],
      "source": [
        "def get_mae_model(num_classes):\n",
        "    from transformers import AutoImageProcessor, AutoModelForPreTraining\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/vit-mae-large\", use_fast=True)\n",
        "    pretrained_model = AutoModelForPreTraining.from_pretrained(\"facebook/vit-mae-large\")\n",
        "    base_model = pretrained_model.vit\n",
        "\n",
        "    classification_head = nn.Linear(base_model.config.hidden_size, num_classes)\n",
        "\n",
        "    class MAEForClassification(nn.Module):\n",
        "        def __init__(self, base_model, classification_head):\n",
        "            super().__init__()\n",
        "            self.base_model = base_model\n",
        "            self.classifier = classification_head\n",
        "\n",
        "        def forward(self, pixel_values, labels=None):\n",
        "            outputs = self.base_model(pixel_values=pixel_values)\n",
        "            pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "            logits = self.classifier(pooled_output)\n",
        "            loss = None\n",
        "            if labels is not None:\n",
        "                loss_fn = nn.CrossEntropyLoss()\n",
        "                loss = loss_fn(logits, labels)\n",
        "            return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "    model = MAEForClassification(base_model, classification_head).to(device)\n",
        "    return model, processor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nprXya1lS-2_"
      },
      "outputs": [],
      "source": [
        "print(\"=== MAE ===\")\n",
        "mae_model, mae_processor = get_mae_model(num_classes)\n",
        "mae_acc = train_and_evaluate(mae_model, mae_processor, train_loader, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC1MXzgBS219"
      },
      "outputs": [],
      "source": [
        "def get_pvt_model(num_classes):\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    from transformers import AutoImageProcessor, PvtForImageClassification\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    processor = AutoImageProcessor.from_pretrained(\"Zetatech/pvt-tiny-224\")\n",
        "    model = PvtForImageClassification.from_pretrained(\n",
        "        \"Zetatech/pvt-tiny-224\",\n",
        "        num_labels=num_classes,\n",
        "        problem_type=\"single_label_classification\",\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    model.to(device)\n",
        "    return model, processor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UWJ90_7S53T"
      },
      "outputs": [],
      "source": [
        "print(\"=== PVT ===\")\n",
        "pvt_model, pvt_processor = get_pvt_model(num_classes)\n",
        "pvt_acc = train_and_evaluate(pvt_model, pvt_processor, train_loader, valid_loader)\n",
        "print(f\"PVT Validation Accuracy: {pvt_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVtNQOw5XBcA"
      },
      "outputs": [],
      "source": [
        "def get_yolos_small_for_classification(num_classes):\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    from transformers import YolosModel, AutoImageProcessor\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-small\")\n",
        "    base_model = YolosModel.from_pretrained(\"hustvl/yolos-small\")\n",
        "\n",
        "    hidden_size = base_model.config.hidden_size\n",
        "    classification_head = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    class YOLOSSmallForClassification(nn.Module):\n",
        "        def __init__(self, base_model, classifier):\n",
        "            super().__init__()\n",
        "            self.base_model = base_model\n",
        "            self.classifier = classifier\n",
        "\n",
        "        def forward(self, pixel_values, labels=None):\n",
        "            outputs = self.base_model(pixel_values=pixel_values, return_dict=True)\n",
        "            pooled_output = outputs.pooler_output  =\n",
        "\n",
        "            logits = self.classifier(pooled_output)\n",
        "            loss = None\n",
        "            if labels is not None:\n",
        "                loss_fn = nn.CrossEntropyLoss()\n",
        "                loss = loss_fn(logits, labels)\n",
        "            return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "    model = YOLOSSmallForClassification(base_model, classification_head).to(device)\n",
        "    return model, processor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-BffwunXDAO"
      },
      "outputs": [],
      "source": [
        "print(\"=== YOLOS ===\")\n",
        "yolos_model, yolos_processor = get_yolos_small_for_classification(num_classes=num_classes)\n",
        "yolos_acc = train_and_evaluate(yolos_model, yolos_processor, train_loader, valid_loader)\n",
        "print(f\"YOLOS Validation Accuracy: {yolos_acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}