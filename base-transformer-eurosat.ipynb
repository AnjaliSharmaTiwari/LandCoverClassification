{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5147765,"sourceType":"datasetVersion","datasetId":2990858}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\n\nfrom timm import create_model\nfrom timm.data.mixup import Mixup\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom torch.cuda.amp import autocast, GradScaler\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:13.913764Z","iopub.execute_input":"2025-01-08T03:16:13.914102Z","iopub.status.idle":"2025-01-08T03:16:27.061357Z","shell.execute_reply.started":"2025-01-08T03:16:13.914069Z","shell.execute_reply":"2025-01-08T03:16:27.060699Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_dir = '/kaggle/input/eurosat10-classes/EuroSAT_RGB/'\n\nimage_paths = glob.glob(os.path.join(data_dir, '*', '*.jpg'))\nlabels = [os.path.basename(os.path.dirname(path)) for path in image_paths]\n\ndf = pd.DataFrame({'image_path': image_paths, 'label': labels})\n\nle = LabelEncoder()\ndf['label_enc'] = le.fit_transform(df['label'])\n\ntrain_df, val_df = train_test_split(\n    df,\n    test_size=0.2,\n    stratify=df['label_enc'],\n    random_state=42\n)\n\nprint(f\"Total images: {len(df)}\")\nprint(f\"Training images: {len(train_df)}\")\nprint(f\"Validation images: {len(val_df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:27.062067Z","iopub.execute_input":"2025-01-08T03:16:27.062264Z","iopub.status.idle":"2025-01-08T03:16:27.916478Z","shell.execute_reply.started":"2025-01-08T03:16:27.062248Z","shell.execute_reply":"2025-01-08T03:16:27.915595Z"}},"outputs":[{"name":"stdout","text":"Total images: 27000\nTraining images: 21600\nValidation images: 5400\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"mean = [0.3444, 0.3809, 0.4082]\nstd = [0.1829, 0.1603, 0.1321]\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:27.917259Z","iopub.execute_input":"2025-01-08T03:16:27.917488Z","iopub.status.idle":"2025-01-08T03:16:27.922800Z","shell.execute_reply.started":"2025-01-08T03:16:27.917469Z","shell.execute_reply":"2025-01-08T03:16:27.921969Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class EuroSATDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df.reset_index(drop=True)\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.df.loc[idx, 'image_path']).convert('RGB')\n        image = self.transforms(image)\n        label = self.df.loc[idx, 'label_enc']\n        return image, label\n\ntrain_dataset = EuroSATDataset(train_df, train_transforms)\nval_dataset = EuroSATDataset(val_df, val_transforms)\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:27.923647Z","iopub.execute_input":"2025-01-08T03:16:27.923859Z","iopub.status.idle":"2025-01-08T03:16:27.940147Z","shell.execute_reply.started":"2025-01-08T03:16:27.923834Z","shell.execute_reply":"2025-01-08T03:16:27.939379Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = create_model(\n    'vit_base_patch16_224',\n    pretrained=True,\n    num_classes=10,\n    drop_rate=0.0,\n    drop_path_rate=0.1 \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:27.940829Z","iopub.execute_input":"2025-01-08T03:16:27.941040Z","iopub.status.idle":"2025-01-08T03:16:31.438667Z","shell.execute_reply.started":"2025-01-08T03:16:27.941022Z","shell.execute_reply":"2025-01-08T03:16:31.437952Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab4453be373a4ae9ad8b8f7b6a8643d4"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(label_smoothing=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:31.441216Z","iopub.execute_input":"2025-01-08T03:16:31.441431Z","iopub.status.idle":"2025-01-08T03:16:31.444896Z","shell.execute_reply.started":"2025-01-08T03:16:31.441412Z","shell.execute_reply":"2025-01-08T03:16:31.444223Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def get_param_groups(model, base_lr, weight_decay):\n    no_weight_decay = model.no_weight_decay()\n    param_groups = {}\n    for name, param in model.named_parameters():\n        if not param.requires_grad:\n            continue\n        group_name = 'layer_0'\n        if 'blocks' in name:\n            block_num = int(name.split('.')[1])\n            group_name = f'layer_{block_num + 1}'\n        elif 'cls_token' in name or 'pos_embed' in name:\n            group_name = 'layer_0'\n        else:\n            group_name = 'layer_0'\n\n        if group_name not in param_groups:\n            param_groups[group_name] = {'params': [], 'weight_decay': weight_decay, 'lr': base_lr}\n        param_groups[group_name]['params'].append(param)\n\n    param_groups_list = []\n    num_layers = len(param_groups)\n    for i, (group_name, group) in enumerate(sorted(param_groups.items(), key=lambda x: x[0])):\n        group['lr'] = base_lr * (0.95 ** (num_layers - i - 1))  \n        param_groups_list.append(group)\n\n    return param_groups_list\n\nbase_lr = 3e-5\nweight_decay = 0.01\noptimizer = AdamW(get_param_groups(model, base_lr, weight_decay))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:31.445970Z","iopub.execute_input":"2025-01-08T03:16:31.446149Z","iopub.status.idle":"2025-01-08T03:16:31.464424Z","shell.execute_reply.started":"2025-01-08T03:16:31.446133Z","shell.execute_reply":"2025-01-08T03:16:31.463839Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:31.465087Z","iopub.execute_input":"2025-01-08T03:16:31.465386Z","iopub.status.idle":"2025-01-08T03:16:31.484968Z","shell.execute_reply.started":"2025-01-08T03:16:31.465345Z","shell.execute_reply":"2025-01-08T03:16:31.484244Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"mixup_fn = Mixup(\n    mixup_alpha=0.8,\n    cutmix_alpha=1.0,\n    cutmix_minmax=None,\n    prob=1.0,\n    switch_prob=0.5,\n    mode='batch',\n    label_smoothing=0.1,\n    num_classes=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:31.485729Z","iopub.execute_input":"2025-01-08T03:16:31.485925Z","iopub.status.idle":"2025-01-08T03:16:31.501349Z","shell.execute_reply.started":"2025-01-08T03:16:31.485898Z","shell.execute_reply":"2025-01-08T03:16:31.500707Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"scaler = GradScaler()\n\ndef train_one_epoch(epoch, model, dataloader, optimizer, criterion, scheduler):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in dataloader:\n        images = images.cuda(non_blocking=True)\n        labels = labels.cuda(non_blocking=True)\n\n        images, labels = mixup_fn(images, labels)\n\n        optimizer.zero_grad()\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        running_loss += loss.item() * images.size(0)\n        total += labels.size(0)\n\n    epoch_loss = running_loss / total\n    print(f'Epoch {epoch} - Training Loss: {epoch_loss:.4f}')\n    return epoch_loss\n\ndef validate(model, dataloader, criterion):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images = images.cuda(non_blocking=True)\n            labels = labels.cuda(non_blocking=True)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item() * images.size(0)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    print(f'Validation Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n    return epoch_loss, epoch_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:31.502223Z","iopub.execute_input":"2025-01-08T03:16:31.502529Z","iopub.status.idle":"2025-01-08T03:16:31.596500Z","shell.execute_reply.started":"2025-01-08T03:16:31.502506Z","shell.execute_reply":"2025-01-08T03:16:31.595489Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-e111d25dae38>:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model = model.cuda()\n\nnum_epochs = 30\nbest_acc = 0.0\n\nfor epoch in range(1, num_epochs + 1):\n    print(f\"Epoch {epoch}/{num_epochs}\")\n    train_loss = train_one_epoch(epoch, model, train_loader, optimizer, criterion, scheduler)\n    val_loss, val_acc = validate(model, val_loader, criterion)\n\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), 'best_vit_model.pth')\n        print(\"Saved Best Model\")\n\n    print('-' * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T03:16:31.597381Z","iopub.execute_input":"2025-01-08T03:16:31.597673Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-10-e111d25dae38>:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_vit_model.pth'))\n\nfor param in model.parameters():\n    param.requires_grad = True\n\nbase_lr = 1e-5\noptimizer = AdamW(get_param_groups(model, base_lr, weight_decay))\n\nscheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n\n\nfor epoch in range(1, num_epochs + 1):\n    print(f\"Fine-tuning Epoch {epoch}/{num_epochs}\")\n    train_loss = train_one_epoch(epoch, model, train_loader, optimizer, criterion, scheduler)\n    val_loss, val_acc = validate(model, val_loader, criterion)\n\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), 'best_vit_model_finetuned.pth')\n        print(\"Saved Fine-Tuned Best Model\")\n\n    print('-' * 30)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_vit_model_finetuned.pth'))\n\nval_loss, val_acc = validate(model, val_loader, criterion)\nprint(f'Final Model Validation Accuracy: {val_acc:.4f}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}